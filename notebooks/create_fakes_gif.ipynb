{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lustre/work/chaselab/malyetama\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORK = os.environ[\"WORK\"]\n",
    "%cd $WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image as Img\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "from pygifsicle import optimize\n",
    "from IPython.display import Markdown, display, Image\n",
    "import dotenv\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "\n",
    "def create_fakes_gif(\n",
    "    DATASET_NAME,\n",
    "    subset=None,\n",
    "    output_dir=None,\n",
    "    ftype='gif',\n",
    "    display_output=False,\n",
    "    verbose=False,\n",
    "    shift={\n",
    "        'shift_r': 0,\n",
    "        'shift_b': 0\n",
    "    }\n",
    "):\n",
    "    \n",
    "    def process(i):\n",
    "        im = Img.open(i)\n",
    "        if DATASET_NAME == 'metfaces':\n",
    "            left, top, right, bottom = 0, 0, (256 * 4) * 2, (256 * 4) * 2\n",
    "        else:\n",
    "            left, top, right, bottom = 1 * shift['shift_r'], 1 * shift[\n",
    "                'shift_b'], (256 * 4) + shift['shift_r'], (256 * 4) + shift['shift_b']\n",
    "        im_cropped = im.crop((left, top, right, bottom))\n",
    "        return im_cropped.save(f'{history}/{Path(i).stem}.png')\n",
    "    \n",
    "    def upload_img(image, token):\n",
    "        with open(image, \"rb\") as file:\n",
    "            url = \"https://api.imgbb.com/1/upload\"\n",
    "            parameters = {\n",
    "                \"key\": token,\n",
    "                \"image\": base64.b64encode(file.read()),\n",
    "            }\n",
    "            res = requests.post(url, parameters)\n",
    "            link = res.json()\n",
    "            url = link['data']['url']\n",
    "            return url\n",
    "\n",
    "    WORK = os.environ[\"WORK\"]\n",
    "    PROJ_DIR = f'{WORK}/ADA_Project'\n",
    "    \n",
    "    dotenv.load_dotenv(f'{PROJ_DIR}/.env')\n",
    "    token = os.getenv('TOKEN')\n",
    "    \n",
    "    history = f'{PROJ_DIR}/datasets/{DATASET_NAME}_history'\n",
    "    try:\n",
    "        shutil.rmtree(history)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    TRfolders = f'{PROJ_DIR}/training_runs/'\n",
    "    TRfolders_ = glob(f'{PROJ_DIR}/training_runs/*')\n",
    "    datasets = [\n",
    "        x.replace(TRfolders, '').replace('_training-runs', '')\n",
    "        for x in TRfolders_\n",
    "    ]\n",
    "    ds_rename = lambda before, after: [after if x == before else x for x in datasets]\n",
    "    datasets = ds_rename('AFHQ', 'AFHQ-CAT')\n",
    "    datasets = [x.replace('_custom', '') for x in datasets]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Available datasets:\\n {datasets}')\n",
    "\n",
    "    d = {}\n",
    "    \n",
    "    with open(f'{PROJ_DIR}/FID_of_best_snapshots.json') as jf:\n",
    "        jd = json.load(jf)\n",
    "        best = 'fakes' + jd[DATASET_NAME]['snapshot'].replace('network-snapshot-', '')\n",
    "\n",
    "    for folder, dataset in zip(TRfolders_, datasets):\n",
    "        files = sorted(glob(folder + \"/**/*\"))\n",
    "        fakes = [x for x in files if 'fakes' in x]\n",
    "        if fakes == []:\n",
    "            continue\n",
    "        d[dataset] = {}\n",
    "        d[dataset]['files'] = fakes[::subset] + [\n",
    "            f'{Path(fakes[-1]).parent}/{best}{Path(fakes[-1]).suffix}']\n",
    "    \n",
    "    Path(history).mkdir(exist_ok=True)\n",
    "    \n",
    "    n_jobs = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    _ = Parallel(n_jobs=n_jobs)(delayed(process)(i)\n",
    "                                     for i in tqdm(d[DATASET_NAME]['files']))\n",
    "\n",
    "    history_imgs = sorted([x for x in glob(f'{history}/*.png')])\n",
    "    history_imgs = [history_imgs[-1]] + [x for x in history_imgs if 'init' not in x]\n",
    "    \n",
    "    \n",
    "    if subset is not None and verbose:\n",
    "        print(f'Subset size: {len(history_imgs)} image')\n",
    "\n",
    "    if output_dir is None:\n",
    "        output_dir = Path.cwd()\n",
    "        anim_file = f'{output_dir}/{DATASET_NAME}.{ftype}'\n",
    "    anim_file = f'{DATASET_NAME}.{ftype}'\n",
    "\n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        for filename in tqdm(history_imgs):\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            if str(Path(filename).stem) == best:\n",
    "                for _ in range(20):\n",
    "                    writer.append_data(image)\n",
    "                break\n",
    "    \n",
    "    file_size = lambda file: Path(file).stat().st_size / 1e+6\n",
    "    if verbose:\n",
    "        if ftype == 'mp4':\n",
    "            print(f'file size: {file_size(anim_file):.2f} MB')\n",
    "        else:\n",
    "            print(f'file size before optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if ftype == 'gif':\n",
    "        optimize(source=anim_file, destination=anim_file)\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'          after optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if display_output is True:\n",
    "        if ftype == 'gif':\n",
    "            print('Loading...')\n",
    "            img_url = upload_img(anim_file, token)\n",
    "            print(f'{ftype} url ==> {img_url}')\n",
    "            display(Markdown(f'![]({img_url})'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      " ['AFHQ-WILD', 'AFHQ-CAT', 'StyleGAN2_FFHQ_30K', 'metfaces', 'POKEMON', 'StanfordDogs', 'StyleGAN2_AFHQ-DOG', 'cars196', 'AFHQ-DOG', 'FFHQ_5K', 'FFHQ_2K', 'ANIME-FACES', 'conditional_CIFAR-10', 'StyleGAN2_FFHQ_5K', 'StyleGAN2_WILD-AFHQ', 'unconditional_CIFAR-10', '102flowers', 'StyleGAN2_FFHQ', 'FFHQ_30K', 'FFHQ', 'StyleGAN2_FFHQ_2K']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'FFHQ_custom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4006d46b9740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     shift={\n\u001b[1;32m     10\u001b[0m         \u001b[0;34m'shift_r'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;34m'shift_b'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m256\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     }\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-36-7e043773df4e>\u001b[0m in \u001b[0;36mcreate_fakes_gif\u001b[0;34m(DATASET_NAME, subset, output_dir, ftype, display_output, verbose, shift)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     _ = Parallel(n_jobs=n_jobs)(delayed(process)(i)\n\u001b[0;32m---> 98\u001b[0;31m                                      for i in tqdm(d[DATASET_NAME]['files']))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mhistory_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{history}/*.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'FFHQ_custom'"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = 'FFHQ_custom'\n",
    "\n",
    "create_fakes_gif(\n",
    "    DATASET_NAME=DATASET_NAME,\n",
    "    display_output=True,\n",
    "    verbose=True,\n",
    "    subset=10,\n",
    "    ftype='mp4',\n",
    "    shift={\n",
    "        'shift_r': 256 * 5,\n",
    "        'shift_b': 256 * 3\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_in = DATASET_NAME + '.mp4'\n",
    "_out = DATASET_NAME + '.gif'\n",
    "! /work/chaselab/malyetama/.conda/envs/ada-env/bin/ffmpeg -i $_in -vf \\\n",
    "    \"fps=10,scale=512:-1:flags=lanczos,split[s0][s1];[s0]palettegen[p];[s1][p]paletteuse\" \\\n",
    "    -loop 0 $_out -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f93300a1cc43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "display(Img(_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StyleGAN2', 'FFHQ', 'custom', '30k']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'StyleGAN2_FFHQ_custom_30k'\n",
    "s.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
