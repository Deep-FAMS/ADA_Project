{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "from pygifsicle import optimize\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def create_fakes_gif(DATASET_NAME, output_dir=None, subset=None, display_gif=False, verbose=False):\n",
    "    \n",
    "    def process(i):\n",
    "        im = Image.open(i)\n",
    "        if DATASET_NAME == 'metfaces':\n",
    "            left, top, right, bottom = 0, 0, 1020 * 2, 1020 * 2\n",
    "        else:\n",
    "            left, top, right, bottom = 0, 0, 1020, 1020\n",
    "        im_cropped = im.crop((left, top, right, bottom))\n",
    "        return im_cropped.save(f'{history}/{Path(i).stem}.jpg')\n",
    "\n",
    "    WORK = os.environ[\"WORK\"]\n",
    "    PROJ_DIR = f'{WORK}/ADA_Project'\n",
    "\n",
    "    TRfolders = f'{PROJ_DIR}/training_runs/'\n",
    "    TRfolders_ = glob(f'{PROJ_DIR}/training_runs/*')\n",
    "    datasets = [\n",
    "        x.replace(TRfolders, '').replace('_training-runs', '')\n",
    "        for x in TRfolders_\n",
    "    ]\n",
    "    ds_rename = lambda before, after: [after if x == before else x for x in datasets]\n",
    "    datasets = ds_rename('AFHQ', 'AFHQ-CAT')\n",
    "    datasets = ds_rename('FFHQ', 'FFHQ_FULL')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Available datasets:\\n {datasets}')\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for folder, dataset in zip(TRfolders_, datasets):\n",
    "        files = sorted(glob(folder + \"/**/*\"))\n",
    "        fakes = [x for x in files if 'fakes' in x]\n",
    "        if fakes == []:\n",
    "            continue\n",
    "        d[dataset] = {}\n",
    "        d[dataset]['files'] = fakes[::subset]\n",
    "    \n",
    "    history = f'{PROJ_DIR}/datasets/{DATASET_NAME}_history'\n",
    "    try:\n",
    "        shutil.rmtree(history)\n",
    "    except:\n",
    "        pass\n",
    "    Path(history).mkdir(exist_ok=True)\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = Path.cwd()\n",
    "\n",
    "    n_jobs = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    _ = Parallel(n_jobs=n_jobs)(delayed(process)(i)\n",
    "                                     for i in tqdm(d[DATASET_NAME]['files']))\n",
    "\n",
    "    history_imgs = sorted([x for x in glob(f'{history}/*.jpg')])\n",
    "    history_imgs = [history_imgs[-1]] + [x for x in history_imgs if 'init' not in x]\n",
    "    \n",
    "    if subset is not None and verbose:\n",
    "        print(f'Subset size: {len(history_imgs)} image')\n",
    "    \n",
    "    anim_file = f'{DATASET_NAME}.gif'\n",
    "\n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        for filename in history_imgs:\n",
    "            image = imageio.imread(filename)\n",
    "            if filename == history_imgs[-1]:\n",
    "                for _ in range(20):\n",
    "                    writer.append_data(image)\n",
    "            writer.append_data(image)\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    \n",
    "    file_size = lambda file: Path(file).stat().st_size / 1e+6\n",
    "    if verbose:\n",
    "        print(f'gif size before optimization: {file_size(anim_file):.2f} MB')\n",
    "    optimize(source=anim_file, destination=anim_file)\n",
    "    if verbose:\n",
    "        print(f'         after optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if display_gif is True:\n",
    "        print('Loading...')\n",
    "        return display(Markdown(f'<img src=\"{anim_file}\" width=\"600\">'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:00<00:00, 2273.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets:\n",
      " ['AFHQ-WILD', 'AFHQ-CAT', 'metfaces', 'StyleGAN2_metfaces', 'POKEMON', 'StanfordDogs', 'StyleGAN2_AFHQ-DOG', 'cars196', 'AFHQ-DOG', 'FFHQ_5K', 'FFHQ_2K', 'ANIME-FACES', 'StyleGAN2_WILD-AFHQ', '102flowers', 'FFHQ_30K', 'FFHQ_FULL']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gif size before optimization: 36.86 MB\n",
      "         after optimization: 9.80 MB\n",
      "Loading...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<img src=\"FFHQ_30K.gif\" width=\"600\">"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_fakes_gif(DATASET_NAME='FFHQ_30K', output_dir=os.environ[\"WORK\"], display_gif=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
