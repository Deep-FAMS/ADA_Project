{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "WORK = os.environ[\"WORK\"]\n",
    "%cd $WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import imageio\n",
    "from pygifsicle import optimize\n",
    "from IPython.display import Markdown, display\n",
    "import dotenv\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "def create_fakes_gif(\n",
    "    DATASET_NAME, subset=None, output_dir=None, display_gif=False, verbose=False):\n",
    "    \n",
    "    def process(i):\n",
    "        im = Image.open(i)\n",
    "        if DATASET_NAME == 'metfaces':\n",
    "            left, top, right, bottom = 0, 0, 1020 * 2, 1020 * 2\n",
    "        else:\n",
    "            left, top, right, bottom = 0, 0, 1020, 1020\n",
    "        im_cropped = im.crop((left, top, right, bottom))\n",
    "        return im_cropped.save(f'{history}/{Path(i).stem}.jpg')\n",
    "    \n",
    "    def upload_img(image, token):\n",
    "        with open(image, \"rb\") as file:\n",
    "            url = \"https://api.imgbb.com/1/upload\"\n",
    "            parameters = {\n",
    "                \"key\": token,\n",
    "                \"image\": base64.b64encode(file.read()),\n",
    "            }\n",
    "            res = requests.post(url, parameters)\n",
    "            link = res.json()\n",
    "            url = link['data']['url']\n",
    "            return url\n",
    "\n",
    "    WORK = os.environ[\"WORK\"]\n",
    "    PROJ_DIR = f'{WORK}/ADA_Project'\n",
    "    \n",
    "    dotenv.load_dotenv(f'{PROJ_DIR}/.env')\n",
    "    token = os.getenv('TOKEN')\n",
    "    \n",
    "    history = f'{PROJ_DIR}/datasets/{DATASET_NAME}_history'\n",
    "    shutil.rmtree(history)\n",
    "\n",
    "    TRfolders = f'{PROJ_DIR}/training_runs/'\n",
    "    TRfolders_ = glob(f'{PROJ_DIR}/training_runs/*')\n",
    "    datasets = [\n",
    "        x.replace(TRfolders, '').replace('_training-runs', '')\n",
    "        for x in TRfolders_\n",
    "    ]\n",
    "    ds_rename = lambda before, after: [after if x == before else x for x in datasets]\n",
    "    datasets = ds_rename('AFHQ', 'AFHQ-CAT')\n",
    "    \n",
    "    if verbose:\n",
    "        print(f'Available datasets:\\n {datasets}')\n",
    "\n",
    "    d = {}\n",
    "\n",
    "    for folder, dataset in zip(TRfolders_, datasets):\n",
    "        files = sorted(glob(folder + \"/**/*\"))\n",
    "        fakes = [x for x in files if 'fakes' in x]\n",
    "        if fakes == []:\n",
    "            continue\n",
    "        d[dataset] = {}\n",
    "        d[dataset]['files'] = fakes[::subset]\n",
    "    \n",
    "    Path(history).mkdir(exist_ok=True)\n",
    "    \n",
    "    n_jobs = multiprocessing.cpu_count() - 1\n",
    "\n",
    "    _ = Parallel(n_jobs=n_jobs)(delayed(process)(i)\n",
    "                                     for i in tqdm(d[DATASET_NAME]['files']))\n",
    "\n",
    "    history_imgs = sorted([x for x in glob(f'{history}/*.jpg')])\n",
    "    history_imgs = [history_imgs[-1]] + [x for x in history_imgs if 'init' not in x]\n",
    "    \n",
    "    with open('best_snapshots.json') as jf:\n",
    "        d = json.load(jf)\n",
    "        best = 'fakes' + d[DATASET_NAME]['snapshot'][17:]\n",
    "    \n",
    "    if subset is not None and verbose:\n",
    "        print(f'Subset size: {len(history_imgs)} image')\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = Path.cwd()\n",
    "        anim_file = f'{output_dir}/{DATASET_NAME}.gif'\n",
    "    anim_file = f'{DATASET_NAME}.gif'\n",
    "\n",
    "    with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "        for filename in tqdm(history_imgs):\n",
    "            image = imageio.imread(filename)\n",
    "            writer.append_data(image)\n",
    "            if str(Path(filename).stem) == best:\n",
    "                for _ in range(20):\n",
    "                    writer.append_data(image)\n",
    "                break\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    \n",
    "    file_size = lambda file: Path(file).stat().st_size / 1e+6\n",
    "    if verbose:\n",
    "        print(f'gif size before optimization: {file_size(anim_file):.2f} MB')\n",
    "    optimize(source=anim_file, destination=anim_file)\n",
    "    if verbose:\n",
    "        print(f'         after optimization: {file_size(anim_file):.2f} MB')\n",
    "    \n",
    "    if display_gif is True:\n",
    "        print('Loading...')\n",
    "        img_url = upload_img(anim_file, token)\n",
    "        display(Markdown(f'![]({img_url})'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_fakes_gif(DATASET_NAME='AFHQ-CAT', display_gif=True, verbose=True, subset=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
