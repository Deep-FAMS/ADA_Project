{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "WORK = os.environ[\"WORK\"]\n",
    "os.chdir(f'{WORK}/ADA_Project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "import DeepFAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_DIR = f'{WORK}/ADA_Project'\n",
    "RAW_IMGS_DIR = f'{PROJ_DIR}/datasets/102flowers_dataset_raw'\n",
    "RESIZED_IMGS_DIR = f'{PROJ_DIR}/datasets/102flowers_resized'\n",
    "DATA_CUSTOM_DIR = f'{PROJ_DIR}/datasets/102flowers_custom'\n",
    "TRAIN_RUNS_DIR = f'{PROJ_DIR}/training_runs/102flowers_training-runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz'\n",
    "# urllib.request.urlretrieve(url, f'{PROJ_DIR}/datasets/102flowers.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarf = tarfile.open(f'{PROJ_DIR}/datasets/102flowers.tgz')\n",
    "# tarf.extractall(path=RAW_IMGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_imgs = glob(f'{RAW_IMGS_DIR}/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in tqdm(raw_imgs):\n",
    "#     DeepFAMS.preprocessing.resize_imgs(x, (256, 256), RESIZED_IMGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepFAMS.preprocessing.tf_record_exporter(tfrecord_dir=DATA_CUSTOM_DIR, image_dir=RESIZED_IMGS_DIR, shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Needs to be run through the command line at least once to compile the model\n",
    "\n",
    "# ! module load anaconda && \\\n",
    "#     module load compiler/gcc/4.7 && \\\n",
    "#     module load cuda && \\\n",
    "#     $WORK/.conda/envs/ada-env/bin/python $WORK/ADA_Project/StyleGAN2-ada__source_code/train.py \\\n",
    "#     --outdir=$WORK/ADA_Project/training_runs/102flowers_training-runs \\\n",
    "#     --gpus=2 \\\n",
    "#     --data=$WORK/ADA_Project/datasets/102flowers_custom \\\n",
    "#     --snap=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/chaselab/malyetama/ada_project/training_runs/102flowers_training-runs/00043-102flowers_custom-auto2-resumecustom/network-snapshot-000008.pkl\n"
     ]
    }
   ],
   "source": [
    "for num in range(-1, -10, -1):\n",
    "    files = DeepFAMS.utils.last_snap(num, TRAIN_RUNS_DIR)\n",
    "    if files != []:\n",
    "        break\n",
    "\n",
    "latest_snap = sorted(files)[-1]\n",
    "print(latest_snap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_desc, training_options = DeepFAMS.setup_training_options(\n",
    "    gpus       = 2,\n",
    "    snap       = 1,\n",
    "    data       = DATA_CUSTOM_DIR,\n",
    "    resume     = latest_snap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 18 12:24:08 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100S-PCI...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 250W |    618MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100S-PCI...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   32C    P0    37W / 250W |    618MiB / 32510MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    299215      C   ...a/envs/ada-env/bin/python      307MiB |\n",
      "|    0   N/A  N/A    299596      C   ...a/envs/ada-env/bin/python      307MiB |\n",
      "|    1   N/A  N/A    299215      C   ...a/envs/ada-env/bin/python      307MiB |\n",
      "|    1   N/A  N/A    299596      C   ...a/envs/ada-env/bin/python      307MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.utils.execute('nvidia-smi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training options:\n",
      "{\n",
      "  \"G_args\": {\n",
      "    \"func_name\": \"training.networks.G_main\",\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"mapping_layers\": 2,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"D_args\": {\n",
      "    \"func_name\": \"training.networks.D_main\",\n",
      "    \"mbstd_group_size\": 4,\n",
      "    \"fmap_base\": 8192,\n",
      "    \"fmap_max\": 512,\n",
      "    \"num_fp16_res\": 4,\n",
      "    \"conv_clamp\": 256\n",
      "  },\n",
      "  \"G_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"D_opt_args\": {\n",
      "    \"beta1\": 0.0,\n",
      "    \"beta2\": 0.99,\n",
      "    \"learning_rate\": 0.0025\n",
      "  },\n",
      "  \"loss_args\": {\n",
      "    \"func_name\": \"training.loss.stylegan2\",\n",
      "    \"r1_gamma\": 0.4096\n",
      "  },\n",
      "  \"augment_args\": {\n",
      "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
      "    \"tune_heuristic\": \"rt\",\n",
      "    \"tune_target\": 0.6,\n",
      "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
      "    \"apply_args\": {\n",
      "      \"xflip\": 1,\n",
      "      \"rotate90\": 1,\n",
      "      \"xint\": 1,\n",
      "      \"scale\": 1,\n",
      "      \"rotate\": 1,\n",
      "      \"aniso\": 1,\n",
      "      \"xfrac\": 1,\n",
      "      \"brightness\": 1,\n",
      "      \"contrast\": 1,\n",
      "      \"lumaflip\": 1,\n",
      "      \"hue\": 1,\n",
      "      \"saturation\": 1\n",
      "    },\n",
      "    \"tune_kimg\": 100\n",
      "  },\n",
      "  \"num_gpus\": 2,\n",
      "  \"image_snapshot_ticks\": 1,\n",
      "  \"network_snapshot_ticks\": 1,\n",
      "  \"train_dataset_args\": {\n",
      "    \"path\": \"/work/chaselab/malyetama/ada_project/datasets/102flowers_custom\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 256,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"metric_arg_list\": [\n",
      "    {\n",
      "      \"name\": \"fid50k_full\",\n",
      "      \"class_name\": \"metrics.frechet_inception_distance.FID\",\n",
      "      \"max_reals\": null,\n",
      "      \"num_fakes\": 50000,\n",
      "      \"minibatch_per_gpu\": 8,\n",
      "      \"force_dataset_args\": {\n",
      "        \"shuffle\": false,\n",
      "        \"max_images\": null,\n",
      "        \"repeat\": false,\n",
      "        \"mirror_augment\": false\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"metric_dataset_args\": {\n",
      "    \"path\": \"/work/chaselab/malyetama/ada_project/datasets/102flowers_custom\",\n",
      "    \"max_label_size\": 0,\n",
      "    \"resolution\": 256,\n",
      "    \"mirror_augment\": false\n",
      "  },\n",
      "  \"total_kimg\": 25000,\n",
      "  \"minibatch_size\": 32,\n",
      "  \"minibatch_gpu\": 16,\n",
      "  \"G_smoothing_kimg\": 10.0,\n",
      "  \"G_smoothing_rampup\": null,\n",
      "  \"resume_pkl\": \"/work/chaselab/malyetama/ada_project/training_runs/102flowers_training-runs/00043-102flowers_custom-auto2-resumecustom/network-snapshot-000008.pkl\",\n",
      "  \"run_dir\": \"/work/chaselab/malyetama/ada_project/training_runs/102flowers_training-runs/00045-102flowers_custom-auto2-resumecustom\"\n",
      "}\n",
      "\n",
      "Output directory:  /work/chaselab/malyetama/ada_project/training_runs/102flowers_training-runs/00045-102flowers_custom-auto2-resumecustom\n",
      "Training data:     /work/chaselab/malyetama/ada_project/datasets/102flowers_custom\n",
      "Training length:   25000 kimg\n",
      "Resolution:        256\n",
      "Number of GPUs:    2\n",
      "\n",
      "Dry run; exiting.\n"
     ]
    }
   ],
   "source": [
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=True, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "DeepFAMS.RunTraining(outdir=TRAIN_RUNS_DIR, seed=1000,\n",
    "             dry_run=False, run_desc=run_desc, training_options=training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ada-env)",
   "language": "python",
   "name": "ada-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
